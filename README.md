# MultiMed: Multilingual Multitask Multipurpose Medical Speech Recognition

> Please press ‚≠ê button and/or cite papers if you feel helpful.

<p align="center">
<img src="https://img.shields.io/badge/Last%20updated%20on-10.04.2024-brightgreen?style=for-the-badge">
<img src="https://img.shields.io/badge/Written%20by-Le%20Duc%20Khai-pink?style=for-the-badge"> 
</p>

<p align="center">
<img src="https://img.shields.io/badge/Speech Recognition-white"> 
<img src="https://img.shields.io/badge/Natural Language Processing-white">
<img src="https://img.shields.io/badge/Machine Learning-white">     
<img src="https://img.shields.io/badge/Deep Learning-white">      
<img src="https://img.shields.io/badge/AI for Healthcare-white">
</p>

## List of implemented papers

<details><summary>VietMed: A Dataset and Benchmark for Automatic Speech Recognition of Vietnamese in the Medical Domain (LREC-COLING 2024) </summary><p>

* [Main page](VietMed/README.md)

* **Abstract:**
Due to privacy restrictions, there's a shortage of publicly available speech recognition datasets in the medical domain. In this work, we present VietMed - a Vietnamese speech recognition dataset in the medical domain comprising 16h of labeled medical speech, 1000h of unlabeled medical speech and 1200h of unlabeled general-domain speech. To our best knowledge, VietMed is by far the world's largest public medical speech recognition dataset in 7 aspects: total duration, number of speakers, diseases, recording conditions, speaker roles, unique medical terms and accents. VietMed is also by far the largest public Vietnamese speech dataset in terms of total duration. Additionally, we are the first to present a medical ASR dataset covering all ICD-10 disease groups and all accents within a country. Moreover, we release the first public large-scale pre-trained models for Vietnamese ASR, w2v2-Viet and XLSR-53-Viet, along with the first public large-scale fine-tuned models for medical ASR. Even without any medical data in unsupervised pre-training, our best pre-trained model XLSR-53-Viet generalizes very well to the medical domain by outperforming state-of-the-art XLSR-53, from 51.8% to 29.6% WER on test set (a relative reduction of more than 40%). All code, data and models are made publicly available here: https://github.com/leduckhai/MultiMed
    
* **Citation:**
Please cite this paper https://arxiv.org/abs/2404.05659

``` bibtex
@inproceedings{VietMed_dataset,
  title={VietMed: A Dataset and Benchmark for Automatic Speech Recognition of Vietnamese in the Medical Domain}, 
  author={Khai Le-Duc},
  year={2024},
  booktitle = {Proceedings of the Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)},
}
```
</p></details>

<details><summary>Medical Spoken Named Entity Recognition (Coming soon!)</summary><p>
Due to the double-blind review at ACL 2024, request of data and models will be processed after paper notification.
</p></details>

<details><summary>Real-time Speech Summarization for Medical Conversations (Coming soon!)</summary><p>
Due to the double-blind review at Interspeech 2024, request of data and models will be processed after paper notification.
</p></details>

<details><summary>Two-Stage Intermediate Loss for Fine-tuning Self-Supervised Models (Coming soon!)</summary><p>
Due to the double-blind review, request of implementation and models will be processed after paper notification.
</p></details>

<details><summary>Domain-Shift in Medical Machine Translation (Coming soon!)</summary><p>
Due to the double-blind review, request of implementation and models will be processed after paper notification.
</p></details>
